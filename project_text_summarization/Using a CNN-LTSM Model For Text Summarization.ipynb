{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Problem\n",
    "\n",
    "Using the [BBC News Summary dataset](https://www.kaggle.com/pariza/bbc-news-summary) from kaggle, we will be using text summarization techniques to generate a fixed length summary of documents. The dataset includes a collection of articles and their corresponsing summary that fall under the given topics: business, entertainment, politics, sport and tech. \n",
    "\n",
    "# State of the Art\n",
    "\n",
    "Text summarization have risen in need over the past years. This is due to the amount of information out in the world and the need to summarize the information in a concise way is needed. In order to do this, two mechanisms are used, extractive and abstractive. Extractive is using term frequency to extract the most important sentences in each document and construct a summary from that. Such techniques include, bayesian topic models or latent semantic analysis (LSA) or you can use frequency driven approaches that use term frequency vectors[3]. The other is abstractive, which uses deep learning models to build out summaries from the document. One such advancement from [1] was to use a convolutional layer on top of an LSTM layers. The main process of abstractive text summarization is to extract key phrases and to build out new sentences, the summary, from that. An advancement in this field was to use a bidirecitonal LSTM connected to a recurrent layer[2]. These solutions, however, do encounter the problem of sparse vectors when training the model. Thus, a lot of research has been done to determine how to solve those problems.\n",
    "\n",
    "# Case Study\n",
    "\n",
    "The process of text summarization is a very hot issue in today's world. The amount of website articles being published and Wikipedia articles is a very high number. So, the need to take the information and condensing it into a much smaller amount of sentences is becoming needed even more. The two approaches, extractive and abstractive are also very important to examine. So, an BiLSTM-RNN model and extractive techniques will be used to determine which approach is the best to solve the problem of text summarization.\n",
    "\n",
    "# Data Analysis\n",
    "\n",
    "The dataset includes articles and summaries spanning over 5 topics. The histogram showing the length of each \n",
    "\n",
    "![Figure 2](article_summary_histogram.png)\n",
    "\n",
    "![Figure_1](article_summary_len.png)\n",
    "\n",
    "# Schedule"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[1] Song, S., Huang, H. & Ruan, T. Abstractive text summarization using LSTM-CNN based deep learning. Multimed Tools Appl 78, 857â€“875 (2019). https://doi.org/10.1007/s11042-018-5749-3\n",
    "\n",
    "[2] Basaldella M., Antolli E., Serra G., Tasso C. (2018) Bidirectional LSTM Recurrent Neural Network for Keyphrase Extraction. In: Serra G., Tasso C. (eds) Digital Libraries and Multimedia Archives. IRCDL 2018. Communications in Computer and Information Science, vol 806. Springer, Cham\n",
    "\n",
    "[3] arXiv:1707.02268"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
